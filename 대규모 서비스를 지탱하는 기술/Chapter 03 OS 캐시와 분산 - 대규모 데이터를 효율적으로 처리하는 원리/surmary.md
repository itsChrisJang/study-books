# Chapter 03 OS 캐시와 분산 - 대규모 데이터를 효율적으로 처리하는 원리
## 대규모 데이터를 다룰 때의 포인트
> I/O 대책에 대한 기반은 OS에 있다.
###  OS 캐시와 분산
- OS 캐시
- 캐시를 전제로 한 I/O 부하 줄이는 방법
- 캐시를 고려한 국소성을 살리는 분산

## 강의 8. OS의 캐시 구조
### 메모리, 디스크, OS 캐시구조

- 디스크와 메모리 간 속도 차는 10^5 ~ 10^10배 이상
- 메모리를 이용해서 디스크 액세스를 줄이고자 한다.
- OS는 캐시 구조를 갖추고 있다.



## OS의 캐시 구조

OS는 메모리를 이용해 디스크 액세스를 줄이는 구조를 갖추고 있습니다. 이러한 구조가 바로 **OS 캐시**입니다. 디스크는 메모리에 비해 훨씬 느리므로, 데이터를 빠르게 읽고 쓸 수 있도록 하는 방법이 필요합니다. OS는 이를 해결하기 위해 캐시 시스템을 사용합니다.

### 페이지 캐시(Page Cache)

- **페이지 캐시**는 Linux 운영 체제에서 사용되는 주요 캐시 구조입니다.
- 페이지 캐시는 디스크의 데이터를 메모리에 저장하여, 다음에 같은 데이터에 접근할 때 디스크를 직접 읽지 않고 메모리에서 빠르게 읽을 수 있도록 합니다.
- 이 방식으로 디스크 접근 횟수를 줄이고 시스템 성능을 향상시킬 수 있습니다.

### 파일 캐시와 버퍼 캐시

- Linux에서는 페이지 캐시뿐만 아니라 **파일 캐시(file cache)**와 **버퍼 캐시(buffer cache)**라는 캐시 구조도 존재합니다.
- 하지만 **파일 캐시**라는 용어는 페이지 캐시와 비슷한 개념을 포함하고 있어 정확한 의미로 사용하기에 부적절한 경우가 많습니다.
- 파일 캐시와 버퍼 캐시는 메모리에서 파일이나 데이터 블록을 캐시하여 디스크 I/O를 줄이는 역할을 하지만, 페이지 캐시가 이들보다 더 중요한 역할을 합니다.

## 강의 9. I/O 부하를 줄이는 방법
### 캐시를 전제로 한 I/O 줄이는 방법
- 강의 8에서 살펴본 바와 같이 캐시에 의한 I/O 경감 효과는 매우 크다. 캐시를 전제로 I/O를 줄이기 위한 대책을 세우는 것이 유효하다는 것을 알 수 있을 것이다. 이것이야말로 I/O 대책의 기본이다. 이 기본으로부터 도출할 수 있는 포인트를 두 가지 소개한다.
- 첫 번째 포인트는 데이터 규모에 비해 물리 메모리가 크면 전부 캐싱할 수 있으므로 이 점을 생각할 것. 다루고자 하는 데이터의 크기에 주목하는 것이다.
- 또한 대규모 데이터 처리에는 데이터 압축이 중요하다고 했는데, 압축해 저장해둔 디스크 내용을 전부 그대로 캐싱해둘 수 있는 경우가 많다. 예를 들어 LZ* 등 일반적인 압축 알고리즘의 경우, 압축률을 보통이라면 텍스트 파일을 대략 절반 정도로 압축할 수 있다. 4GB의 텍스트 파일이라면 메모리 2GB만 쓰도록 뒷받침 정도는 거의 캐싱할 수 없었던 것이, 압축해서 저장해두면 2GB로 캐싱할 수 있는 비율이 상당히 늘어나게 된다.
- 또 하나는 경제적인 비용과의 밸런스를 고려하고자 한다는 점이다. 최근에는 메모리가 8GB~16GB 정도가 일반적인 서버 한 대의 메모리 구성이다. 최근의 서버는 남들게 대체적으로 메모리가 8GB~16GB 정도 탑재되어 있다. AP 서버는 메모리가 그렇게 많이 필요하지는 않으므로 4GB 정도지만, DB 서버는 그 정도의 메모리가 탑재되어 있다.
- 이 부분을 짚질해 보고 있는 시점이 2009년 9월에 메모리의 시장 가격은 2GB 단품 모듈이 2,000엔 정도이므로 8GB를 탑재해도 1만 엔이 되지 않는다. 굉장한 시대인 것 같다. 필자가 인프라 관련 일을 중점적으로 하고 있을 때가 2년쯤 전인데 그 당시에는 8GB는 좀 비싸서 3~4만 엔 정도였는데, 지금은 1만 엔에 채 안 된다. 열심히 소프트웨어를 개발해서 "그래, 이건 데이터 크기를 엄청 줄여서 캐싱하도록 할 수 있을 거야" 라며 5명을 반 년 정도 투입해서 대단한 압축 알고리즘을 생각해냈다. 그런데 애초에 8GB 메모리만 더 들어갔다면 사실 1만 엔 정도밖에 들지 않으므로 비용적으로 굳이 그렇게까지 하지 않아도 되는 일이었다. 따라서 시장에서는 어느 정도 성능의 서버가 일반적인 제품인지도 중요하다.
- 한편, 요즘은 하나에 2GB의 메모리와 4GB의 메모리의 가격이 전혀 다르다. 그러므로 메모리가 32GB나 64GB 정도 되어야 캐싱할 수 있다고 할 때, 하드웨어 비용이 급격히 높아지므로 소프트웨어로 메모리 사용을 줄일 수 있도록 노력할 필요도 있다.
> ### Memo
> - 데이터 규모 < 물리 메모리이면 전부 캐싱할 수 있다.
> - 경제적 비용과의 밸런스 고려
> - 현재 일반적인 서버 메모리: 8GB~16GB 

### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
- 메모리를 늘려서 전부 캐싱할 수 있다면 좋겠지만, 당연히 데이터를 전부 캐싱할 수 없는 규모가 될 수 있다. 그렇게 되면 어떻게 할 것인가? 여기서 먼저 복수 서버로 확장시키는 방안을 생각해볼 필요가 있다.
- 강의 6의 그림 2.5에서 언급한 것처럼, AP 서버, DB 서버라는 3단 구조에 대한 복수화. 그림 3.10을 보기 바란다. 그림 3.10의 ① AP 서버를 늘려야 하는 이유는 기본적으로 CPU 부하를 낮추고 분산시키기 위함이다. 한편, 그림 3.10 ②의 DB 서버를 늘려야 할 때는 반드시 부하 때문만은 아니고 오히려 캐시 용량을 늘리고자 할 때 혹은 효율을 높이고자 할 때일 경우가 많다.
- 따라서 그림 3.10 ① AP 서버를 늘리는 것과 ② DB 서버를 늘리는 것은 둘 다 서버를 늘리는 것이지만 필요한 리소스, 요구되는 리소스가 전혀 다르다. DB 서버는 '늘리면 좋다'라는 논리가 들어맞지 않는다. 그림 3.10 ② 부분에 DB 서버를 엄청나게 늘려서 100대로 늘린 사람의 방식에 따라서는 생각보다 효과를 거둘 수 없게 된다.
![서버_증설과_부하](image/서버_증설과_부하.png)
> #### 전부 캐싱할 수 없는 구조가 되면
> - 복수 서버로 확장시키기
>     - CPU 부하 분산에는 단순히 늘린다.
>     - I/O 분산에는 국소성을 고려한다.

## 강의 9: I/O 부하 줄이기 방법

### 캐시를 전제로 한 I/O 줄이기 전략
- **데이터 규모 < 물리 메모리**인 경우, 전체 데이터를 캐싱할 수 있어 디스크 I/O가 최소화됨.
- 대규모 데이터는 **압축(LZ, zip 등)**하여 캐시할 데이터 양을 줄일 수 있음.
- 메모리 증설은 소프트웨어 최적화보다 경제적일 때가 많음(단, 32GB, 64GB 이상은 비용 증가 고려).

### 복수 서버로 확장 시 고려사항
- 단순 복제만으로는 캐시 문제 해결이 어려움.
- 캐시할 수 없는 부분(디스크 I/O)은 서버 수 증가에 따라 반복되어 병목 현상이 발생할 수 있음.

## 강의 10: 국소성을 살리는 분산

### 국소성 기반 분산 전략
- **데이터 액세스 패턴**을 고려하여 서버를 분리.
    - 예: 인기 엔트리 요청은 DB 서버1, 개인 북마크 요청은 DB 서버2로 분산.
- 각 서버는 자신에게 필요한 데이터의 캐시 적중률을 높일 수 있음.

### 파티셔닝(Partitioning)
- **테이블 단위 분할**: 자주 함께 사용되는 테이블은 한 서버에, 나머지는 다른 서버에 분산.
- **테이블 데이터 분할**: 하나의 테이블 내 레코드를 사용자 ID 등 기준으로 분할하여 여러 서버에 분산.

### 요청 패턴별 서버 그룹(섬) 분할
- HTTP 요청의 **User-Agent**나 **URL** 등을 기준으로 서버 그룹(섬)을 구성.
    - 예: 검색 봇은 별도 섬으로 분리, 일반 사용자는 인기 페이지 중심의 캐시 활용.
- 이를 통해 캐시 효율을 최적화하고, 캐싱하기 어려운 요청이 다른 서버에 영향을 주지 않도록 함.

### 페이지 캐시 운용 규칙
- OS 기동 직후에는 캐시가 없으므로 서버를 바로 투입하지 않음.
- 미리 주요 DB 파일을 읽어 캐시를 채운 후, 서버를 로드 밸런서에 포함시킴.
- 성능 평가는 캐시가 최적화된 이후의 상태에서 실시해야 함.

## 제3장의 강의 포인트 요약

- **국소성(locality)** 기반의 분석 필요.
- **데이터 규모**에 맞춰 적절한 메모리 증설 고려.
- 메모리 증설로 해결이 어려운 경우에는 **분산 처리** 방안을 모색.

## Column: sar 명령어를 통한 OS 지표 확인

### sar 명령어 사용 예시
- **CPU 사용률 확인 (`sar -u`)**
    - %user: 사용자 모드 CPU 사용률
    - %system: 커널 모드 CPU 사용률
    - %iowait: I/O 대기로 인한 Idle 비율
    - %idle: 유휴 상태 비율
- **메모리 사용 현황 확인 (`sar -r`)**
    - kbmemfree: 남은 물리 메모리 (KB)
    - kbmemused: 사용 중인 물리 메모리 (KB)
    - %memused: 메모리 사용률
    - kbcached: 페이지 캐시로 사용 중인 메모리 (KB)
    - kbbuffers: 커널 내 버퍼로 사용 중인 메모리 (KB)
- **스왑 발생 상황 확인 (`sar -W`)**
    - pswpin/s: 초당 스왑 인 (페이지 단위)
    - pswpout/s: 초당 스왑 아웃 (페이지 단위)
- 스왑이 과도하게 발생하면 성능 저하가 발생하므로, 메모리 부족 시점을 파악하는 데 유용함.

## Column: 페이지 캐시와 I/O 부하

- **페이지 캐시 동작 원리**
    - 디스크에서 데이터를 읽어 페이지 캐시를 생성.
    - 메모리가 남아 있으면 캐시를 계속 유지, 부족하면 오래된 캐시를 제거.
    - 부팅 후 시간이 지나면 대부분의 파일이 자연스럽게 캐시에 올라감.
- **캐시 효과**
    - 전체 데이터를 캐시에 담을 수 있으면, 디스크 액세스 없이 메모리 I/O로 처리되어 성능이 크게 향상됨.
    - 예: MySQL 서버에서 메모리 증설 시 %iowait 감소.

## Column: 부하분산과 OS 동작 원리

- OS의 **가상 메모리, 페이지 캐시, 멀티프로세스/멀티스레드, 파일 시스템** 등의 기본 동작 원리를 이해해야 함.
- 이러한 이해를 바탕으로 서버 확장 및 부하분산 전략을 효과적으로 수립할 수 있음.